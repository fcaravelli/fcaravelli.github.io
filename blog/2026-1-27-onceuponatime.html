<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <title>Once upon a time.. I wanted to learn about dimer models – Francesco Caravelli</title>
  <link rel="stylesheet" href="../assets/css/style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&family=Inter:wght@300;500;700&display=swap" rel="stylesheet">

  <style>
    p.math { margin: 1rem 0; }
    img.hero { max-width: 100%; height: auto; border-radius: 12px; }
    .note { font-size: 0.95rem; opacity: 0.9; }
    .hr { height: 1px; background: rgba(0,0,0,0.12); margin: 1.25rem 0; }
  </style>

  <!-- AdSense: load ONCE per page -->
  <script async
    src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6719988103594554"
    crossorigin="anonymous"></script>

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"></script>

  <script defer>
    function renderKatexIn(el) {
      if (!el || typeof renderMathInElement !== "function") return;
      renderMathInElement(el, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "\\[", right: "\\]", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\(", right: "\\)", display: false }
        ],
        throwOnError: false,
        macros: { "\\mathbbm": "\\mathbb" },
        ignoredTags: ["script", "noscript", "style", "textarea", "pre", "code"]
      });
    }

    document.addEventListener("DOMContentLoaded", () => {
      renderKatexIn(document.querySelector("main.content"));
    });
  </script>
</head>

<body>
  <div class="layout">
    <!-- Sidebar -->
    <div id="sidebar"></div>

    <main class="content">

      <!-- In-article AdSense Ad -->
      <ins class="adsbygoogle"
           style="display:block"
           data-ad-format="fluid"
           data-ad-layout-key="-ef+6k-30-ac+ty"
           data-ad-client="ca-pub-6719988103594554"
           data-ad-slot="9710109684"></ins>
      <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

<section id="onceuponatime">

  <h3>Once upon a time.. I wanted to learn about dimer models</h3>
  <p><em>January 27, 2026</em></p>

  <img class="hero" src="images/onceuponatime.png" alt="Once upon a time hero image">

 <p>Recently Nature Communications published <a href="https://www.nature.com/articles/s41467-025-67568-w">online</a> a manuscript that we started when I was 
still in Los Alamos. I must say that I was very excited to see it published. In particular, I need to praise a lot the first author, Pratik Sathe, who incidentally is now working a scientist at D-Wave.</p>

<p>I am inspired in writing this blog post in the style of the Once upon a time in America style.. this is essentially a post about my old (LANL) friends.</p>
  <p>
    The paper I want to discuss about is titled <a href="https://www.nature.com/articles/s41467-025-67568-w">Classical criticality via quantum annealing</a>, and it describes how we used a D-Wave quantum annealer
    to reconstruct a full finite-temperature phase diagram and do finite-size scaling for a frustrated Ising model with an exact solution.  

  </p>
  <p> In many ways, the paper is a continuation (and yet also not) of previous work I had done <a href="https://arxiv.org/pdf/2201.11598">here</a>, in a paper published in Physica A.
      Around 2020 I wanted to learn how to solve statistical mechanics problems in 2D using the Kasteleyn solution. 

      I remember spending days reading Kasteleyn's original papers and trying to understand how to implement the solution for arbitrary models.
      I finally discovered that there was a paper by Montroll that described it, in a book which is very hard to find that is called Combinatorial Mathematics.
      One day I was wondering in the Santa Fe Library and found the book there, casually sitting in between two graph theory books (the Santa Fe Library is one of the best small libraries I have seen.)
      Two of the problems I solved there (including a one parameter subfamily of the 16 vertex model) used the Kasteleyn mapping of the Ising model,
      initially introduced by Michael Fisher for the 2D Ising model. 
      The problem I worked on was an extension of the Ising model, an interpolation between the 2D ferromagnetic Ising model and the fully frustrated Ising model solved by Villain in 1977. This particular interpolation is
       called the piled-up dominoes (PUD) model. In my Physica A I called it Onsager-Villain.
             </p>

      It is defined by the Hamiltonian: 

    <p class="math">
      $$
      H(s) = (1-s) H_{\text{2D Ising}} + s H_{\text{Villain}}.
      $$
    </p>
      where \(H_{\text{2D Ising}}\) is the standard ferromagnetic Ising Hamiltonian on the square lattice and \(H_{\text{Villain}}\) is the fully frustrated Ising model solved by Villain in 1977. Solving this problem means finding the partition function (or the free energy).

      In fact, I did not know of the existence of the solution of this model to 1979, after Villain's solution of the fully frustrated model in 1977. Pratik actually found the paper only a few months before we finished the draft of the D-Wave paper.
      That problem was actually inspired by a conversation that Yigit Subasi and I had in 2018 with Helmut Katzgraber while he was visiting Los Alamos, who told us that we should focus
      on that Villain's problem (we were working on something else then). Long story short, I mapped the problem to dimers, solved it, and then looked for nonanalytical points of the partition function.
      I have sent the interpolating parameter s (between 0 and 1 in my paper in Physica A) and found Onsager's 2D critical temperature and called it a victory.
      I actually never bothered to check the solution with Monte Carlo (I did with mathematica though from the exact solution at that time) until I suggested to Pratik
      to attempt to do it with D-Wave. I just wanted to briefly describe how this mapping works.
  </p>

<section id="ising-to-dimers">
  <h4>Solving a planar 2D Ising model via the dimer (Pfaffian) mapping</h4>
  <p class="note">
    First, one needs to map the Ising model to a dimer model. I used  the (Fisher–)Dubédat decoration + Kasteleyn/Pfaffian route, which generates a lattice smaller than the original Fisher one. 
    This is what I used in the Physica A paper, but there are lots of papers doing this. Here we go.
  </p>

  <h5>0) Start from a planar Ising model</h5>
  <p>
    First, take a planar graph <span class="math">\(G=(V,E)\)</span> with spins <span class="math">\(\sigma_v\in\{\pm1\}\)</span> and couplings
    <span class="math">\(J_e\)</span> on edges <span class="math">\(e\in E\)</span>:
  </p>
  <p class="math">
    $$
    Z_{\text{Ising}}(G,J)
    = \sum_{\{\sigma\}}
    \exp\!\Big(\sum_{e=(u,v)\in E} J_e\,\sigma_u\sigma_v\Big).
    $$
  </p>

  <h5>1) High-temperature expansion (the “even subgraphs” step)</h5>
  <p>
    Use <span class="math">\(e^{J\sigma_u\sigma_v}=\cosh(J)\big(1+\sigma_u\sigma_v\tanh(J)\big)\)</span>.
    Expanding the product over edges forces an even number of selected incident edges at each vertex (closed loops / even subgraphs).
    The whole point of the decoration is to turn those even-subgraph constraints into perfect matchings (dimers). 
  </p>

  <h5>2) Fisher–Dubédat decoration: map the Ising graph to a planar dimer graph</h5>
  <p>
    Build a decorated planar graph <span class="math">\(G^{FD}\)</span> by replacing each Ising vertex of degree <span class="math">\(D\)</span>
    with a planar gadget made of <span class="math">\(D\)</span> triangles (Dubédat’s variant; see the decoration discussion/figures in the Physica A paper). 
    Edges of <span class="math">\(G^{FD}\)</span> come in two types:
  </p>
  <ul>
    <li><strong>Decoration edges</strong> (internal to the gadget)</li>
    <li><strong>External edges</strong> corresponding to original Ising edges <span class="math">\(e\in E\)</span></li>
  </ul>

  <h5>3) Assign dimer weights \(\nu_e\)</h5>
  <p>
    Give each edge <span class="math">\(e\)</span> in the decorated graph a weight <span class="math">\(\nu_e\)</span> as: 
  </p>
  <p class="math">
    $$
    \nu_e =
    \begin{cases}
      1, & e\ \text{is a decoration (internal) edge},\\[4pt]
      \tanh(J_e), & e\ \text{corresponds to an original Ising edge},\\[4pt]
      0, & \text{otherwise}.
    \end{cases}
    $$
  </p>

  <h5>4) Ising ↔ dimer partition functions</h5>
  <p>
    With this construction, the Ising partition function factorizes into a simple product times a weighted dimer partition function:
  </p>
  <p class="math">
    $$
    Z_{\text{Ising}}(G,J)
    = \Big(\prod_{e\in E}\cosh(J_e)\Big)\,
      Z_{\text{dimer}}\!\big(G^{FD},\{\nu_e\}\big).
    $$
  </p>

  <h5>5) Kasteleyn orientation and the antisymmetric matrix \(A\)</h5>
  <p>
    Because <span class="math">\(G^{FD}\)</span> is planar, you can choose a Kasteleyn orientation (every face has an odd number of clockwise-oriented edges).
    Then define an antisymmetric “Kasteleyn matrix” <span class="math">\(A\)</span> by
    <span class="math">\(A_{ij}=+\nu_{ij}\)</span> if <span class="math">\(i\to j\)</span> is oriented, and
    <span class="math">\(A_{ij}=-\nu_{ij}\)</span> if <span class="math">\(j\to i\)</span> is oriented (and <span class="math">\(A_{ii}=0\)</span>).
    The dimer partition function is a Pfaffian:
    <span class="math">\(Z_{\text{dimer}}=\mathrm{Pf}(A)\)</span> (so <span class="math">\(Z_{\text{dimer}}^2=\det A\)</span>). This is exactly the mapping 
    that Caianello introduced and that I talked about in a few blog posts ago.
  </p>

  <h5>6) Translational invariance: Fourier-block reduction \(A(\theta,\phi)\)</h5>
  <p>
    If the decorated lattice is periodic (torus) and built by repeating one motif (unit cell), reorder vertices so that
    <span class="math">\(A\)</span> becomes block-circulant. Then the Fourier transform block-diagonalizes it, yielding a small matrix
    <span class="math">\(A(\theta,\phi)\)</span> (size = number of vertices in the motif). The dependence is:
  </p>
  <p class="math">
    $$
    A(\theta,\phi)=A_0
      +A_y^{+}e^{i\theta}+A_y^{-}e^{-i\theta}
      +A_x^{+}e^{i\phi}+A_x^{-}e^{-i\phi}.
    $$
  </p>
  <p>
    Here <span class="math">\(A_0\)</span> encodes edges entirely inside the motif, while
    <span class="math">\(A_x^{\pm}\)</span> and <span class="math">\(A_y^{\pm}\)</span> encode edges crossing to the right/left and up/down neighboring motifs,
    with the appropriate oriented weights <span class="math">\(\pm\nu_e\)</span>. 
  </p>

  <h5>7) Partition function / free energy from \(\det A(\theta,\phi)\)</h5>
  <p>
    In the thermodynamic limit, the log-determinant per unit cell becomes a Brillouin-zone integral. In my paper’s notation,
    one writes the dimer contribution as an integral of <span class="math">\(\log\det A(\theta,\phi)\)</span> over <span class="math">\([0,2\pi]^2\)</span>. 
    A clean way to state it is in terms of the free energy density:
  </p>
  <p class="math">
    $$
    f \equiv \frac{1}{|V|}\log Z_{\text{Ising}}
    = \frac{1}{|V|}\sum_{e\in E}\log\cosh(J_e)
      + \frac{1}{2(2\pi)^2}\int_{0}^{2\pi}\!\!\int_{0}^{2\pi}
        d\theta\,d\phi\;\log\det A(\theta,\phi),
    $$
  </p>
  <p>
    where the factor <span class="math">\(\tfrac12\)</span> is the “Pfaffian square-root” (since <span class="math">\(Z_{\text{dimer}}=\sqrt{\det A}\)</span> up to the standard boundary-condition subtleties on the torus).
    This is exactly the workflow used in the paper: decorate → orient (Kasteleyn) → build motif matrix → Fourier reduce → integrate <span class="math">\(\log\det\)</span>. 
  </p>

  <div class="hr"></div>
  <p class="note">
    Practical tip: the “hard part” in real life is bookkeeping the motif (vertex ordering + which edges cross the unit-cell boundaries).
    Once you have <span class="math">\(A_0, A_x^\pm, A_y^\pm\)</span>, everything downstream is automatic.
  </p>
</section>

<section id="dwave-ising-criticality">
  <p>I wrote that Physica A paper essentially for fun: whose business is not research, does not find. 
    The next step was the mapping to D-Wave. I actually knew about this possibility because of papers that Carleton Coffrin, Marc Vuffray, Sidhant Misra and Andrey Lokhov had written in the past about this (and others).
    What we did not know was how to tune the temperature for Gibbs sampling.
  </p>

  <div class="hr"></div>

  <p>
    Essentially, that is what we did, but it took a lot of work to do that, which is why I think that without Pratik we would have not been able. 
    We essentially used a D-Wave quantum annealer as a <em>statistical physics engine</em>, or rather a sample generator, 
    to reconstruct a full finite-temperature phase diagram and to do honest-to-goodness finite-size scaling —
    including Binder cumulant crossings — for a frustrated Ising model that has an exact solution as described above and for which we 
    see whether the hardware reproduces textbook critical exponents and phase diagrams.
  </p>

  <p>
    It has to be said that in principle there is no reason why this should work. A D-Wave machine is a bunch of superconducting flux qubits wired up so you can program an Ising Hamiltonian.
    The “quantum annealing” protocol starts from an easy initial Hamiltonian (basically a big transverse field),
    then slowly morphs into your problem Hamiltonian, and finally you measure all qubits in the \(Z\) basis to get
    a classical spin configuration \(\{\sigma_i = \pm 1\}\).
  </p>

  <p>
    In the idealized story, you’d stay adiabatically in the ground state and solve optimization problems.
    But here’s the twist: if you run in the <strong>incoherent / long-anneal regime</strong>
    (tens to hundreds of microseconds), the device is strongly coupled to its environment, the dynamics are not
    perfectly adiabatic, and the output distribution often looks like a <strong>thermal (Gibbs/Boltzmann) distribution</strong>
    for the programmed classical Ising model. In this regime, D-Wave annealers can be used for sampling, e.g. generating spin configurations to perform
    averages, as in Monte Carlo.
  </p>

  <p class="note">
    This “D-Wave behaves like a Gibbs sampler in the microsecond regime” viewpoint is not a vibes-based claim —
    it has a real literature (effective-temperature estimation, noisy Gibbs sampling, and explicit high-quality Gibbs sampling
    demonstrations are all in the references).
  </p>

  <p>
    In statistical mechanics, if you want to locate a second-order phase transition and extract universal quantities
    (critical points, exponents, universality class), you usually do Markov-chain Monte Carlo and then run the finite-size machinery:
    Binder cumulants, scaling collapse, susceptibility peaks moving with size, etc.
  </p>

  <p>
    The annoying part is that near critical points, lots of classical samplers slow down (critical slowing down),
    and frustrated systems make everything worse. So the question becomes:
    can a quantum annealer, used as a sampler, reproduce <em>thermal</em> criticality
    in a controlled way — and can we do it with the same tools people use in textbooks?
  </p>

  <p>
    We used the <strong>piled-up dominoes (PUD)</strong> model, which is basically an Ising model on a square lattice
    whose couplings are arranged so that you can continuously interpolate between:
  </p>
  <ul>
    <li>the ferromagnetic 2D Ising model (which has a thermal phase transition), and</li>
    <li>Villain’s fully-frustrated “odd model” (which, in this family, does not show a standard transition in the same way).</li>
  </ul>

  <p>
    This is exactly the model I was describing earlier. Here, the interpolation parameter is \(s\). The Hamiltonian, specifically, can be written as
  </p>

  <p class="math">
    $$
    H(s) = (1-s) H_{\text{2D Ising}} + s H_{\text{Villain}}.
    $$
  </p>

  <p>
    In practice, this just means “two types of nearest-neighbor couplers” on the square grid:
    most are ferromagnetic, and one set of vertical columns has coupling \(1-2s\),
    so as you dial s you "dial" or tune frustration.
  </p>

  <p>
    Now, while a quantum annealer has some physical temperature, but you don’t get to turn a knob labeled “set temperature to 1.73”.
    So we do something else: we scale the energy of the programmed Hamiltonian which dimensionally has the same effect.
  </p>

  <p>
    If the device samples (approximately) from
    \(p(\sigma) \propto e^{-\beta_{\text{sampler}} H_{\text{input}}(\sigma)}\),
    and you program
  </p>

  <p class="math">$$H_{\text{input}} = J\, H,$$</p>

  <p>
    then the effective inverse temperature for the model \(H\) is
  </p>

  <p class="math">$$\beta_{\text{eff}} = J\,\beta_{\text{sampler}} \quad\Rightarrow\quad T_{\text{eff}} \propto J^{-1}.$$</p>

  <p>
    Translation: <strong>scan \(J\) and you scan temperature</strong>. That’s what let us map a phase diagram on hardware, but up to a single point that you need to use for scale.
    What we do in the paper we set the value of the \(s=0) point which corresponds to Onsager's temperature, and check the consistency of the others.
  </p>

  <p>
    To sanity-check everything, we first look at the usual order parameters.
    For a configuration with \(N\) spins:
  </p>

  <p class="math">$$m = \frac{1}{N}\sum_i \sigma_i,$$</p>

  <p>
    and for the antiferromagnetic/staggered one:
  </p>

  <p class="math">$$m_{\text{AFM}} = \frac{1}{N}\sum_i (-1)^{x_i+y_i}\,\sigma_i.$$</p>

  <p>
    Sweeping \((s, J^{-1})\) gives you the expected “ferro / para / AFM” regions
    (for us this was on a periodic 12×12 torus as a headline plot),
    with boundaries that line up nicely with the exact solution. 
  </p>

  <p>
    Notice that while order parameters are nice for pictures, but if you want to locate critical points robustly on finite systems,
    you use Binder cumulants. There are multiple versions of this, the one we used is
  </p>

  <p class="math">
    $$
    U = 1 - \frac{\langle m^4 \rangle}{3\langle m^2 \rangle^2}.
    $$
  </p>

  <p>
    In Monte Carlo, typically you plot \(U(T)\) for different system sizes and look for the crossing.
    We did exactly that on the annealer — except our “temperature axis” is \(J^{-1}\).
    For each \(s\) we ran multiple sizes (tori and skew-tori), generated lots of samples, computed moments,
    and extracted the crossing point \(J_c\). 
  </p>

  <p>
    Long story short, we compared those extracted critical points against the exact \(T_c(s)\) of the PUD model and checked
    the self-consistency of the linear relation \(T \propto J^{-1}\).
    That’s one of the important part:s it’s how we justify that the “temperature knob” is real and meaningful.
  </p>

  <p>
    The next layer is finite-size scaling (FSS). Near a continuous transition you have a diverging correlation length
    \(\xi\) and susceptibility \(\chi\), and critical exponents \(\nu\) and \(\gamma\).
    On finite systems, you look at how peak locations shift with system size and how peak heights scale.
  </p>

  <p>
    On hardware, there’s a practical nuisance: we don’t directly know \(\beta\) and thus we can’t report \(\chi\) in
    absolute physical units. But we can compute things like
  </p>

  <p class="math">$$\frac{\chi}{\beta} = N\left(\langle m^2\rangle - \langle m\rangle^2\right),$$</p>

  <p>
    and do the scaling analysis with those peak features (plus some care about how the \(T\leftrightarrow J^{-1}\) mapping enters).
    We find that extracting exponents is noticeably more delicate than locating \(J_c\),
    because these quantities depend on <em>fourth moments</em> and are more sensitive to experimental imperfections.
  </p>

  <h4>Calibration refinement (“shimming”): unsexy, mandatory, and totally worth it</h4>

  <p>
    This is an underrated but important point. Quantum annealers are analog devices. That means small biases, coupler errors, crosstalk, and noise are always lurking.
    If you’re just doing “find low energies”, you can sometimes brute-force around it.
    If you’re doing Binder cumulants and susceptibilities, you don’t get that luxury - Andrew King is the one who introduced this technique and coached us quite a lot on this.
  </p>

  <p>
    So we used calibration refinement (a.k.a. shimming): adjust flux-bias offsets and coupler shims with an adaptive procedure,
    and smooth the corrections across energy scales.
    The practical takeaway is simple: <strong>if you want clean critical behavior out, you need to fight the hardware a bit.</strong>
  </p>

  <h4>Why is this relevant at all? No critical slowing down (at least in the way MCMC suffers)</h4>

  <p>
    Here’s one of my favorite conceptual points which was actually also one of the selling aspects of this work. In single-spin-flip MCMC, near \(T_c\) you get long autocorrelation times:
    consecutive samples are very correlated, so you need tons of updates to get independent data.
  </p>

  <p>
    On the annealer, each sample is generated by reinitializing the device and running a fresh anneal.
    That “reset” means samples are <em>designed</em> to be (approximately) independent,
    and any residual correlations are mostly device-level artifacts rather than algorithmic slow mixing.
  </p>

  <p>
    We explicitly compared an autocorrelation function for QA samples against Metropolis MCMC near criticality
    (for the largest QA size we used, 12×12). The MCMC autocorrelation decays slowly (as expected);
    QA sits near a small, roughly flat value — i.e., no obvious diverging correlation time in the sampling stream.
  </p>

  <ul>
    <li>Thus, a quantum annealer can reproduce a <strong>full finite-temperature phase diagram</strong> of a nontrivial frustrated Ising family, not just ground states.</li>
    <li>You can do <strong>Binder cumulant crossings</strong> and extract critical points on hardware.</li>
    <li>With enough care (including calibration refinement), you can push toward <strong>finite-size scaling</strong> analyses of critical behavior.</li>
    <li>The sampling workflow shows <strong>no classical-style critical slowing down</strong> in the time-series sense that plagues basic MCMC near second-order transitions.</li>
  </ul>

  <p>
    If we can reliably treat annealers as temperature-tunable samplers for programmable Ising models,
    then you can start using them as experimental platforms for equilibrium statistical mechanics — especially where
    classical sampling gets painful (frustration, glassiness, huge degeneracy, awkward constraints). To be honest, there was also a paper that
    came shortly after ours by G. Teza et al, doing some similar work but only for the 2D ferromagnetic Ising model. They actually find better critical
    exponents than us (more precise), but we show a full phase diagram reconstruction quite precisely.
  </p>

  <p>
    The obvious bottlenecks right now are (i) device size/connectivity and (ii) the cost of the calibration refinement loop.
    But hardware is moving fast, and the methodology is now pretty concrete:
    “program a model → calibrate → sweep energy scale → compute cumulants and FSS observables.”
  </p>

  <p class="note">
    If you’re reading this because you want to replicate the workflow:
    the key ingredients are (1) periodic boundary conditions (tori / skew-tori), (2) lots of samples per point,
    (3) careful temperature-by-energy-scale sweeps, and (4) shimming when you’re using high-order moments.
  </p>
</section>


      <!-- Second ad block (NO second AdSense script include) -->
      <ins class="adsbygoogle"
           style="display:block; text-align:center;"
           data-ad-layout="in-article"
           data-ad-format="fluid"
           data-ad-client="ca-pub-6719988103594554"
           data-ad-slot="2406334732"></ins>
      <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

      <p><a href="../blog.html">← Back to Blog</a></p>

    </main>
  </div>

  <script>
    async function loadSidebar() {
      const sidebarContainer = document.getElementById('sidebar');
      const response = await fetch('../partials/sidebar.html');
      const html = await response.text();
      sidebarContainer.innerHTML = html;

      const currentPath = window.location.pathname.split('/').pop();
      const links = sidebarContainer.querySelectorAll('a');
      links.forEach(link => {
        if (link.getAttribute('href') === currentPath) {
          link.classList.add('active');
        }
      });

      // Re-render KaTeX in case the injected sidebar contains math
      if (typeof renderMathInElement === "function") {
        renderMathInElement(document.querySelector("main.content"), {
          delimiters: [
            { left: "$$", right: "$$", display: true },
            { left: "\\[", right: "\\]", display: true },
            { left: "$", right: "$", display: false },
            { left: "\\(", right: "\\)", display: false }
          ],
          throwOnError: false,
          macros: { "\\mathbbm": "\\mathbb" },
          ignoredTags: ["script", "noscript", "style", "textarea", "pre", "code"]
        });
      }
    }
    loadSidebar();
  </script>
</body>
</html>
