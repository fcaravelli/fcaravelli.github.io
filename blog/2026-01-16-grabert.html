<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <title>Grabert-Mori-Zwanzig and the Jarzynski equality – Francesco Caravelli</title>
  <link rel="stylesheet" href="../assets/css/style.css" />
  <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@400;700&family=Inter:wght@300;500;700&display=swap" rel="stylesheet">

  <!-- Optional: nice spacing for display-math blocks -->
  <style>
    p.math { margin: 1rem 0; }
  </style>

  <!-- AdSense: load ONCE per page -->
  <script async
    src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6719988103594554"
    crossorigin="anonymous"></script>

  <!-- KaTeX (fast TeX rendering) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"></script>

  <script defer>
    function renderKatexIn(el) {
      if (!el || typeof renderMathInElement !== "function") return;
      renderMathInElement(el, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "\\[", right: "\\]", display: true },
          { left: "$", right: "$", display: false },
          { left: "\\(", right: "\\)", display: false }
        ],
        throwOnError: false,
        // Helps if you use \mathbbm{1} somewhere; KaTeX doesn't ship bbm by default
        macros: {
          "\\mathbbm": "\\mathbb"
        },
        ignoredTags: ["script", "noscript", "style", "textarea", "pre", "code"]
      });
    }

    document.addEventListener("DOMContentLoaded", () => {
      renderKatexIn(document.querySelector("main.content"));
    });
  </script>
</head>

<body>
  <div class="layout">
    <!-- Sidebar -->
    <div id="sidebar"></div>

    <main class="content">

      <!-- In-article AdSense Ad -->
      <ins class="adsbygoogle"
           style="display:block"
           data-ad-format="fluid"
           data-ad-layout-key="-ef+6k-30-ac+ty"
           data-ad-client="ca-pub-6719988103594554"
           data-ad-slot="9710109684"></ins>
      <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

      <h2>(Grabert-)Mori-Zwanzig and the Jarzynski equality - Francesco Caravelli</h2>

      January 16, 2026<br/><br/>

      <p>
        For some time now I've been working on a side project (which as many are now in my Overleaf) which involves fluctuation theorems and the Mori-Zwanzig approach
        to coarse graining. Today I'd like to discuss a bit about the connection between the two, which I find quite fascinating.
        The Mori-Zwanzig formalism is a powerful technique in statistical mechanics that allows us to derive
        effective equations of motion for a subset of variables in a complex system by
        integrating out the remaining degrees of freedom.
        This is particularly useful when dealing with systems that have a large number of interacting components,
        as it enables us to focus on the relevant variables while still accounting for the influence of the others via noise and memory.
        The derivation is not too hard. I will actually give it here in two different ways, and then I will focus on the Grabert approach to MZ.
        What I want to show is that the JE can be derived in a few lines from that. We will begin with the Grabert approach to Mori-Zwanzig
      </p>

      <section id="grabert-relevant-distribution-projectors">

        <h3>Grabert’s “relevant” distribution and projectors</h3>

        <p>
          Let’s start with a classical Hamiltonian system. A microstate lives in phase space
          $\Gamma=(\mathbf q,\mathbf p)$, and the Hamiltonian may depend on time, $H(\Gamma,t)$.
          Microscopic dynamics is Hamiltonian flow:
        </p>

        <p class="math" id="eq-flow">
        \[
          \Gamma_t = \Phi_t(\Gamma_0).
        \]
        </p>

        <p>This flow is generated by the (time-dependent) Liouville operator</p>

        <p class="math" id="eq-liouville">
        \[
          iL(t)\,X(\Gamma)=\{X(\Gamma),H(\Gamma,t)\}.
        \]
        </p>

        <p>
          where $\{\cdot,\cdot\}$ is the classical Poisson bracket. One detail that will play a central role later
          (Jarzynski, and also the relations we’ll derive in the same spirit) is that Hamiltonian evolution preserves
          phase-space volume: $d\Gamma_t=d\Gamma_0$.
        </p>


        <p>
          A coarse-grained description starts by deciding which macroscopic observables you want to track. In Grabert’s
          setup you choose a set of “relevant” observables
          $\{A_1(\Gamma),\dots,A_n(\Gamma)\}$ and you record their instantaneous macroscopic values as expectations under
          the <em>true</em> microscopic distribution $\rho(\Gamma,t)$:
        </p>

        <p class="math" id="eq-ai-def">
        \[
          a_i(t)=\int d\Gamma\,\rho(\Gamma,t)\,A_i(\Gamma).
        \]
        </p>

        <p>
          The point is: if the only information you keep at time $t$ is the set of numbers $\{a_i(t)\}$, then everything
          else about the full microstate distribution is “unknown” from the coarse-grained viewpoint.
        </p>

        <p>
          Grabert’s prescription is to build the statistical state that best represents the system given only those
          constraints: maximize Shannon entropy subject to the conditions above. The result is the familiar exponential
          family
        </p>

        <p class="math" id="eq-exponential0">
        \[
          \bar\rho(\Gamma,t)
          =
          \frac{1}{Z(t)}
          \exp\!\left[-\lambda_i(t)\,A_i(\Gamma)\right].
        \]
        </p>

        <p>
          where the $\lambda_i(t)$ are Lagrange multipliers enforcing the constraints, and $Z(t)$ normalizes the density:
        </p>

        <p class="math" id="eq-Z">
        \[
          Z(t)=\int d\Gamma\,\exp\!\left[-\lambda_i(t)\,A_i(\Gamma)\right].
        \]
        </p>

        <p>
          In Grabert’s approach, the non-equilibrium entropy associated with this relevant distribution is just the
          Shannon entropy:
        </p>

        <p class="math" id="eq-Shannon">
        \[
          S(t)
          =
          -k_B\int d\Gamma\,\bar\rho(\Gamma,t)\,\ln\bar\rho(\Gamma,t).
        \]
        </p>

        <p>For the exponential family above, you get the key thermodynamic identities</p>

        <p class="math" id="eq-entropy-identity">
        \[
          \frac{S(t)}{k_B}
          =
          \ln Z(t) + \lambda_i(t)\,a_i(t),
          \qquad
          \lambda_i(t)=\frac{1}{k_B}\frac{\partial S}{\partial a_i(t)}.
        \]
        </p>

        <p>
          These are telling you something important: the multipliers $\lambda_i(t)$ behave as generalized thermodynamic
          conjugates to the macroscopic variables $a_i(t)$.
        </p>


        <p>
          The second ingredient is a <em>time-dependent projection operator</em> $P(t)$ acting on observables (i.e. functions
          of phase space). Intuitively, $P(t)$ extracts the part of any observable $X(\Gamma)$ that is fixed once you know
          the relevant variables and their fluctuations at time $t$.
        </p>

        <p class="math" id="eq-projector-def">
        \[
          P(t)X
          =
          \langle X\rangle_{\mathrm{rel},t}
          +
          \bigl(A_j(\Gamma)-a_j(t)\bigr)
          \int d\Gamma'\,
          \frac{\partial \bar\rho(\Gamma',t)}{\partial a_j(t)}\,
          X(\Gamma').
        \]
        </p>

        <p>where Grabert’s relevant average is</p>

        <p class="math" id="eq-rel-avg">
        \[
          \langle X\rangle_{\mathrm{rel},t}
          =
          \int d\Gamma\,\bar\rho(\Gamma,t)\,X(\Gamma).
        \]
        </p>

        <p>This projector satisfies a generalized idempotency property</p>

        <p class="math" id="eq-P-idempotency">
        \[
          P(t)\,P(t')=P(t').
        \]
        </p>

        <p>
          The complementary projector is $Q(t)=\mathbb{1}-P(t)$, and it extracts what’s “irrelevant”:
          $Q(t)X=X-P(t)X$. So every observable decomposes as $X=P(t)X+Q(t)X$.
        </p>


        <p>The bridge is the natural pairing between a density $\rho(\Gamma)$ and an observable $X(\Gamma)$:</p>

        <p class="math" id="eq-pairing">
        \[
          \langle \rho, X\rangle
          =
          \int d\Gamma\,\rho(\Gamma)\,X(\Gamma).
        \]
        </p>

        <p>The dual projector $P^\dagger(t)$ is defined so that</p>

        <p class="math" id="eq-dual-projector-def">
        \[
          \langle P^\dagger(t)\rho,\;X\rangle
          =
          \langle \rho,\;P(t)X\rangle
          \qquad\text{for all densities $\rho$ and observables $X$.}
        \]
        </p>

        <p>If $\rho(\Gamma,t)$ is the true microscopic density, the dual projector extracts its relevant part:</p>

        <p class="math" id="eq-rho-rel">
        \[
          \rho_{\mathrm{rel}}(\Gamma,t)\equiv P^\dagger(t)\rho(\Gamma,t).
        \]
        </p>

        <p>And $\bar\rho(\Gamma,t)$ is a fixed point of the dual projector:</p>

        <p class="math" id="eq-fixed-point-dual">
        \[
          P^\dagger(t)\,\bar\rho(\Gamma,t)=\bar\rho(\Gamma,t).
        \]
        </p>

        <p>
          The complementary dual projector is $Q^\dagger(t)=\mathbb{1}-P^\dagger(t)$, so
          $Q^\dagger(t)\rho=\rho-P^\dagger(t)\rho$.
        </p>

      </section>

<section id="mz-classical-time-dependent-projector">

  <h3>The classical Mori–Zwanzig equation with a time-dependent projector</h2>

  <p>
    Now let’s do the “mechanics” part: derive the classical Mori–Zwanzig equation when the projector itself depends
    on time, $P(t)$. I’ll keep everything purely in phase-space language. All operators below act on classical
    observables $X(\Gamma)$, evolving under microscopic Hamiltonian flow.
  </p>


  <p>
    Let $\Gamma_t=\Phi_t(\Gamma_0)$ be the Hamiltonian flow generated by a possibly time-dependent Hamiltonian
    $H(\Gamma,t)$. The Liouville operator acts by the Poisson bracket:
  </p>

  <p class="math" id="eq-iL-classical">
  \[
    iL(t)\,X(\Gamma)=\{X(\Gamma),H(\Gamma,t)\}.
  \]
  </p>

  <p>
    In the classical “Heisenberg picture”, an observable evolves just by composing with the flow:
  </p>

  <p class="math" id="eq-Heisenberg-classical">
  \[
    X(t,\Gamma_0)=X(\Phi_t(\Gamma_0)).
  \]
  </p>

  <p>
    Equivalently, it satisfies the differential equation
  </p>

  <p class="math" id="eq-Heisenberg-eq-classical">
  \[
    \frac{d}{dt}\,X(t,\Gamma_0)=iL(t)\,X(t,\Gamma_0).
  \]
  </p>

  <p>
    It’s convenient to package this into a propagator $U(t,s)$ acting on observables, defined by $X(t)=U(t,s)X(s)$.
    It satisfies
  </p>

  <p class="math" id="eq-propagator-classical">
  \[
    \frac{d}{dt}U(t,s)=iL(t)\,U(t,s),\qquad U(s,s)=\mathbbm{1}.
  \]
  </p>

  <p>
    The other structural fact we keep using is that Hamiltonian flow preserves phase-space measure:
  </p>

  <p class="math" id="eq-measure-preservation">
  \[
    \int d\Gamma\,X(\Gamma)=\int d\Gamma\,X(\Phi_t(\Gamma)).
  \]
  </p>

   <p> In Grabert's approach, the projectors are time dependent, and they are consistent with the geometry of the relevant manifold and Mori-Zwanzig theory.</p>
  <p>
    Let $P(t)$ be Grabert’s projector and $Q(t)=\mathbbm{1}-P(t)$ its complement. Acting on observables,
    $P(t)$ picks out the “relevant” component, while $Q(t)$ captures fluctuations relative to the relevant manifold.
  </p>

  <p>
    It’s worth making the geometry explicit now, because it clarifies why the formulas look the way they do.
    At fixed time $t$, the relevant distribution $\bar\rho(\Gamma,t)$ induces the Mori inner product
    on observables:
  </p>

  <p class="math" id="eq-mori-ip-here">
  \[
    (X,Y)_t
    \equiv
    \bigl\langle X\,Y\bigr\rangle_{\mathrm{rel},t}
    =
    \int d\Gamma\,\bar\rho(\Gamma,t)\,X(\Gamma)\,Y(\Gamma).
  \]
  </p>

  <p>
    In particular, define the covariance matrix of the relevant variables,
  </p>

  <p class="math" id="eq-covariance-matrix-here">
  \[
    C_{ij}(t)
    \equiv
    \bigl(\delta A_i,\delta A_j\bigr)_t
    =
    \Bigl\langle
      \delta A_i\,\delta A_j
    \Bigr\rangle_{\mathrm{rel},t},
    \qquad
    \delta A_i = A_i-a_i(t).
  \]
  </p>

  <p>
    Up to the factor $k_B$, $C_{ij}(t)$ is the restriction of the Fisher information metric to the relevant manifold
    defined by the exponential family $\bar\rho(\Gamma,t)$.
  </p>

  <p>
    With this notation, Grabert’s projector takes the “standard Mori” form
  </p>

  <p class="math" id="eq-P-geometric">
  \[
    P(t)X
    =
    \bigl(X,1\bigr)_t
    +
    \delta A_i\,
    \bigl(C(t)^{-1}\bigr)_{ij}\,
    \bigl(\delta A_j,X\bigr)_t.
  \]
  </p>

  <p>
    This expression makes the meaning transparent: $P(t)$ is the orthogonal projector (in the Fisher/Mori metric)
    onto the relevant subspace $\mathrm{span}\{1,\delta A_1,\dots,\delta A_n\}$, and $Q(t)$ extracts the component
    orthogonal to all relevant variables. Dually, the adjoint $P^\dagger(t)$ acting on densities realizes the
    Fisher-orthogonal projection onto the relevant exponential manifold.
  </p>

  <p>
    As in the case of the standard Mori-Zwanzig approach, the main technical identity we need is a time-dependent Dyson decomposition for the propagator:
  </p>

  <p class="math" id="eq-dyson-classical">
  \[
    U(t,0)
    =
    U(t,0)P(t)
    + \int_0^t ds\, U(s,0)\bigl[P(s)iL(s)Q(s)-\dot P(s)\bigr]G(s,t)
    + Q(0)\,G(0,t).
  \]
  </p>

  <p>
    Here $G(s,t)$ is the <em>orthogonal propagator</em>,
  </p>

  <p class="math" id="eq-G-classical">
  \[
    G(s,t)
    = \exp_R\!\left[\int_s^t dt'\,\, iL(t')Q(t')\right],
  \]
  </p>

  <p>
    i.e. it evolves fluctuations while keeping them orthogonal to the relevant manifold at all intermediate times.
    The final term, $Q(0)G(0,t)$, is the part that propagates the initially irrelevant degrees of freedom forward in
    time — this is where “noise” enters the coarse-grained dynamics.
  </p>


  <p>
    Define the microscopic fluctuations of the relevant variables as
  </p>

  <p class="math" id="eq-deltaA-def-time">
  \[
    \delta A_i(t,\Gamma_0)=A_i(\Gamma_t)-a_i(t),
  \]
  </p>

  <p>
    where $a_i(t)=\int d\Gamma\,\bar\rho(\Gamma,t)\,A_i(\Gamma)$ is the relevant average.
  </p>

  <p>
    Now apply the Dyson identity to the “Liouvillian force” $iL(t)A_i$, keep only the relevant component by acting
    with $P(t)$, and subtract the evolution of the macroscopic averages $\dot a_i(t)$. The outcome is the exact
    classical Mori–Zwanzig equation (a generalized Langevin equation):
  </p>

  <p class="math" id="eq-MZ-classical">
  \[
    \delta\dot{A}_i(t)
    =
    \Omega_{ij}(t)\,\delta A_j(t)
    +
    \int_0^t ds\, \phi_{ij}(t,s)\,\delta A_j(s)
    +
    F_i(t,0).
  \]
  </p>

  <p>
    Each piece has a pretty clean interpretation.
  </p>

  <p>
    The first term is the organized (reversible, Markovian) drift projected onto the relevant manifold:
  </p>

  <p class="math" id="eq-Omega-classical">
  \[
    \Omega_{ij}(t)
    =
    \int d\Gamma\,
    \frac{\partial\bar\rho(\Gamma,t)}{\partial a_j(t)}\,
    iL(t)A_i(\Gamma).
  \]
  </p>

  <p>
    Next comes the memory kernel. This is the term that tells you how past fluctuations feed back into the present
    through orthogonal evolution:
  </p>

  <p class="math" id="eq-phi-classical">
  \[
    \begin{split}
      \phi_{ij}(t,s)
      &=
      \int d\Gamma\,
      \frac{\partial\bar\rho(\Gamma,s)}{\partial a_j(s)}\,
      iL(s)Q(s)\,G(s,t)\,iL(t)A_i(\Gamma)
      \\
      &\quad
      - \dot a_k(s)
      \int d\Gamma\,
      \frac{\partial^2\bar\rho(\Gamma,s)}{\partial a_j(s)\partial a_k(s)}\,
      G(s,t)\,iL(t)A_i(\Gamma).
    \end{split}
  \]
  </p>

  <p>
    Finally, the fluctuating force (the “noise term”) is
  </p>

  <p class="math" id="eq-F-classical">
  \[
    F_i(t,0)=Q(0)\,G(0,t)\,iL(0)A_i.
  \]
  </p>

  <p>
    As in the usual Mori–Zwanzig story, $F_i(t,0)$ captures the contribution of the initial fast degrees of freedom
    that remain irrelevant for all subsequent times. A fundamental property, coming straight from the definition of
    $P(t)$, is the orthogonality condition
  </p>

  <p class="math" id="eq-F-orthogonality">
  \[
    \langle F_i(t,0)\rangle_{\bar\rho(t)} = 0.
  \]
  </p>

  <p>
    So the fluctuating force does not contribute to the organized drift.
  </p>


  <p>
    If you average the generalized Langevin equation over the relevant distribution $\bar\rho(\Gamma,t)$, the
    fluctuating term drops out and you get an exact, closed equation for the macroscopic variables:
  </p>

  <p class="math" id="eq-macro-eq">
  \[
    \dot a_i(t)
    =
    v_i(t)
    +
    \int_0^t ds\,K_i(t,s)
    +
    f_i(t).
  \]
  </p>

  <p>
    Here
  </p>

  <p class="math" id="eq-vi-def">
  \[
    v_i(t)
    =
    \int d\Gamma\,\bar\rho(\Gamma,t)\,iL(t)A_i(\Gamma)
  \]
  </p>

  <p>
    is the organized drift,
  </p>

  <p class="math" id="eq-Ki-def">
  \[
    K_i(t,s)
    =
    \int d\Gamma\,
    \bar\rho(\Gamma,s)\,
    iL(s)Q(s)\,G(s,t)\,iL(t)A_i(\Gamma)
  \]
  </p>

  <p>
    is the macroscopic memory kernel, and
  </p>

  <p class="math" id="eq-fi-def">
  \[
    f_i(t)
    =
    \int d\Gamma\,\rho(\Gamma,0)\,F_i(t,0)(\Gamma)
  \]
  </p>

  <p>
    is the averaged fluctuating force. In particular, it vanishes if the initial microscopic distribution equals
    the relevant distribution:
  </p>

  <p class="math" id="eq-fi-vanish">
  \[
    \rho(\Gamma,0)=\bar\rho(\Gamma,0)
    \quad\Rightarrow\quad
    f_i(t)=0.
  \]
  </p>

  <p>
    The equation above  is the fully classical Grabert–Mori–Zwanzig equation: an <em>exact</em> evolution law
    for coarse-grained variables incorporating reversible drift, memory, and fluctuating contributions generated by
    the orthogonal dynamics.
  </p>

</section>

<section id="entropy-production-ft-grabert">

  <h2>Entropy production and a fluctuation theorem in the classical Grabert framework</h2>

  <p>
    Now we can finally talk about the object I actually care about here: an entropy-production functional that drops
    out almost for free once you adopt Grabert’s “relevant distribution” viewpoint. The punchline is an integral
    fluctuation theorem. And then, with one canonical choice of relevant variable (the energy), that theorem collapses
    directly to Jarzynski’s equality.
  </p>

  <p>
    We work on classical phase space with coordinate $\Gamma$, and Hamiltonian flow
    $\Gamma \mapsto \Gamma_t=\Phi_t(\Gamma)$ generated by $H(\Gamma,t)$. The key structural input is the
    measure-preserving property of Hamiltonian evolution:
  </p>

  <p class="math" id="eq-measure-preservation-ft">
  \[
    \int d\Gamma\, f(\Phi_t(\Gamma))
    =
    \int d\Gamma\, f(\Gamma)
    \quad
    \text{for all suitable } f.
  \]
  </p>

  <p>
    A coarse-grained description is specified by relevant observables $\{A_i(\Gamma)\}_{i=1}^n$ and their macroscopic
    values
  </p>

  <p class="math" id="eq-ai-ft">
  \[
    a_i(t)=\int d\Gamma\,\rho(\Gamma,t)\,A_i(\Gamma),
  \]
  </p>

  <p>
    where $\rho(\Gamma,t)$ is the true microscopic distribution.
  </p>

  <p>
    Grabert’s rule is: if at time $t$ the only information we retain is $\{a_i(t)\}$, the “best” statistical state is
    the maximum-entropy (Shannon) distribution compatible with those constraints — the relevant distribution
  </p>

  <p class="math" id="eq-classical-relevant">
  \[
    \bar\rho(\Gamma,t)
    =
    \exp\bigl[-\Phi(t)-\lambda_i(t)\,A_i(\Gamma)\bigr].
  \]
  </p>

  <p>
    Here the scalar $\Phi(t)$ and the Lagrange multipliers $\lambda_i(t)$ are fixed by normalization and the
    constraints:
  </p>

  <p class="math" id="eq-constraints-relevant">
  \[
    \int d\Gamma\,\bar\rho(\Gamma,t)=1,
    \qquad
    a_i(t)=\int d\Gamma\,\bar\rho(\Gamma,t)\,A_i(\Gamma).
  \]
  </p>

  <p>
    For any observable $X(\Gamma)$, the associated “Grabert average” is simply the expectation with respect to
    $\bar\rho(\Gamma,t)$:
  </p>

  <p class="math" id="eq-grabert-classical-average">
  \[
    \langle X\rangle_{\mathrm{rel},t}
    \equiv
    \int d\Gamma\,\bar\rho(\Gamma,t)\,X(\Gamma).
  \]
  </p>

  <p>
    The non-equilibrium entropy associated with the relevant distribution is the Shannon entropy
  </p>

  <p class="math" id="eq-S-rel">
  \[
    S(t)
    =
    -k_B\int d\Gamma\,\bar\rho(\Gamma,t)\,\ln\bar\rho(\Gamma,t).
  \]
  </p>

  <p>
    If you substitute the exponential form of $\bar\rho$, you get
  </p>

  <p class="math" id="eq-S-identity-ft">
  \[
    \frac{S(t)}{k_B}
    =
    \Phi(t)+\lambda_i(t)\,a_i(t),
  \]
  </p>

  <p>
    and the multipliers are the thermodynamic conjugates:
  </p>

  <p class="math" id="eq-lambda-conjugates-ft">
  \[
    \lambda_i(t)=\frac{1}{k_B}\frac{\partial S}{\partial a_i(t)}.
  \]
  </p>

  <p>
    From now on, we assume the initial microscopic state is the relevant one:
  </p>

  <p class="math" id="eq-initial-condition-rel">
  \[
    \rho(\Gamma,0)=\bar\rho(\Gamma,0).
  \]
  </p>

  <p>
    So initial averages are Grabert averages:
  </p>

  <p class="math" id="eq-initial-rel-average">
  \[
    \langle X\rangle_{\mathrm{rel},0}
    \equiv
    \int d\Gamma_0\,\bar\rho(\Gamma_0,0)\,X(\Gamma_0).
  \]
  </p>

  <p>
    A classical trajectory is specified by an initial point $\Gamma_0$ and its time evolution
    $\Gamma_t=\Phi_t(\Gamma_0)$. Define the <em>dimensionless entropy production</em> along that trajectory by
  </p>

  <p class="math" id="eq-DeltaS-classical-def">
  \[
    \Delta S(\Gamma_0;t)
    \equiv
    \ln\frac{\bar\rho(\Gamma_0,0)}{\bar\rho(\Gamma_t,t)}.
  \]
  </p>

  <p>
    Equivalently,
  </p>

  <p class="math" id="eq-exp-minus-DeltaS">
  \[
    e^{-\Delta S(\Gamma_0;t)}
    =
    \frac{\bar\rho(\Gamma_t,t)}{\bar\rho(\Gamma_0,0)}.
  \]
  </p>

  <p>
    This definition is nice because it’s written entirely in terms of the relevant distributions at the initial and
    final times.
  </p>

  <p>
    Using $\bar\rho(\Gamma,t)=\exp[-\Phi(t)-\lambda_i(t)A_i(\Gamma)]$, you can expand $\Delta S$ explicitly as
  </p>

  <p class="math" id="eq-DeltaS-basic-classical">
  \[
    \Delta S(\Gamma_0;t)
    =
    \bigl[\Phi(t)-\Phi(0)\bigr]
    +\lambda_i(t)\,A_i(\Gamma_t)
    -\lambda_i(0)\,A_i(\Gamma_0).
  \]
  </p>

  <p>
    And with the thermodynamic identity $\frac{S}{k_B}=\Phi+\lambda_i a_i$, you can rewrite this purely in terms of
    the entropy change and the boundary deviations from the relevant averages. First note that
  </p>

  <p class="math" id="eq-Phi-diff">
  \[
    \Phi(t)-\Phi(0)
    =
    \frac{S(t)-S(0)}{k_B}
    -\lambda_i(t)\,a_i(t)+\lambda_i(0)\,a_i(0),
  \]
  </p>

  <p>
    which turns the entropy production into
  </p>

  <p class="math" id="eq-DeltaS-thermo-classical">
  \[
    \Delta S(\Gamma_0;t)
    =
    \frac{S(t)-S(0)}{k_B}
    +\lambda_i(t)\bigl(A_i(\Gamma_t)-a_i(t)\bigr)
    -\lambda_i(0)\bigl(A_i(\Gamma_0)-a_i(0)\bigr).
  \]
  </p>

  <p>
    So $\Delta S$ splits into a macroscopic contribution $(S(t)-S(0))/k_B$, plus boundary terms measuring how the
    microscopic state “enters and leaves” the coarse-grained description determined by $\{A_i\}$.
  </p>

  <p>
    The integral fluctuation theorem is the clean statement
  </p>

  <p class="math" id="eq-ift-statement">
  \[
    \bigl\langle e^{-\Delta S(t)}\bigr\rangle_{\mathrm{rel},0}=1.
  \]
  </p>

  <p>
    The proof is basically one line once you lean on the measure-preserving property. Start from the definition
    $\Delta S(\Gamma_0;t)=\ln\frac{\bar\rho(\Gamma_0,0)}{\bar\rho(\Gamma_t,t)}$ and compute
  </p>

  <p class="math" id="eq-ift-start">
  \[
    \bigl\langle e^{-\Delta S(t)}\bigr\rangle_{\mathrm{rel},0}
    =
    \int d\Gamma_0\,\bar\rho(\Gamma_0,0)\,e^{-\Delta S(\Gamma_0;t)}.
  \]
  </p>

  <p>
    Plugging in $e^{-\Delta S}=\bar\rho(\Gamma_t,t)/\bar\rho(\Gamma_0,0)$ gives
  </p>

  <p class="math" id="eq-ift-cancel">
  \[
    \bigl\langle e^{-\Delta S(t)} \bigr\rangle_{\mathrm{rel},0}
    =
    \int d\Gamma_0\,\bar\rho(\Gamma_t,t).
  \]
  </p>

  <p>
    Now change variables from $\Gamma_0$ to $\Gamma_t=\Phi_t(\Gamma_0)$. Since the flow preserves volume,
    $d\Gamma_0=d\Gamma_t$, so
  </p>

  <p class="math" id="eq-ift-finish">
  \[
    \bigl\langle e^{-\Delta S(t)} \bigr\rangle_{\mathrm{rel},0}
    =
    \int d\Gamma_t\,\bar\rho(\Gamma_t,t)
    =
    1,
  \]
  </p>

  <p>
    because $\bar\rho(\Gamma,t)$ is normalized at every time $t$. That’s the classical integral fluctuation theorem:
  </p>

  <p class="math" id="eq-ift-boxed">
  \[
    \bigl\langle e^{-\Delta S(t)} \bigr\rangle_{\mathrm{rel},0}=1.
  \]
  </p>

  <p>
    You can also re-derive the same identity by starting from the coarse-grained expression for $\Delta S$ and using
    $\frac{S}{k_B}=\Phi+\lambda_i a_i$ to show that all prefactors cancel exactly — i.e. the theorem also reflects the
    internal thermodynamic consistency of Grabert’s construction, not just normalization.
  </p>


  <p>
    In this approach, the second law follows from the JE as usual. Once you have
    $1=\langle e^{-\Delta S(t)}\rangle_{\mathrm{rel},0}$, Jensen’s inequality immediately gives the “second law” form
  </p>

  <p class="math" id="eq-second-law">
  \[
    \langle \Delta S(t)\rangle_{\mathrm{rel},0}\ge 0,
    \qquad
    \Delta\Sigma = k_B\,\Delta S.
  \]
  </p>

  <p>
    Now specialize to the simplest (and most famous) choice: take the energy as the only relevant observable and put
    the system in contact with a heat bath at fixed temperature $T$. Let the Hamiltonian depend on an externally
    controlled protocol $\lambda_t$:
  </p>

  <p class="math" id="eq-H-protocol">
  \[
    H_t(\Gamma)\equiv H(\Gamma,\lambda_t).
  \]
  </p>

  <p>
    Choose
  </p>

  <p class="math" id="eq-A-energy-choice">
  \[
    A(\Gamma)=H(\Gamma,\lambda),
    \qquad
    \lambda(t)\equiv \beta=\frac{1}{k_B T},
  \]
  </p>

  <p>
    so the relevant distribution becomes the canonical ensemble
  </p>

  <p class="math" id="eq-canonical-relevant">
  \[
    \bar\rho(\Gamma,t)
    =
    \frac{1}{Z(t)}\exp\bigl[-\beta H(\Gamma,\lambda_t)\bigr],
  \]
  </p>

  <p>
    with partition function
  </p>

  <p class="math" id="eq-Z-canonical">
  \[
    Z(t)=\int d\Gamma\,\exp\bigl[-\beta H(\Gamma,\lambda_t)\bigr].
  \]
  </p>

  <p>
    In this canonical case, $\Phi(t)=\ln Z(t)$. The instantaneous equilibrium free energy associated with the relevant
    state is
  </p>

  <p class="math" id="eq-free-energy">
  \[
    F(t)=-k_B T\ln Z(t)
    =
    -\frac{1}{\beta}\ln Z(t)
    =
    -\beta^{-1}\Phi(t),
  \]
  </p>

  <p>
    and the free-energy difference is
  </p>

  <p class="math" id="eq-DeltaF">
  \[
    \Delta F
    =
    F(t)-F(0)
    =
    -\frac{1}{\beta}\ln\frac{Z(t)}{Z(0)}.
  \]
  </p>

  <p>
    Along a trajectory $\Gamma_0\mapsto \Gamma_t$, the microscopic work performed by the protocol is just the change
    in the Hamiltonian:
  </p>

  <p class="math" id="eq-work-def">
  \[
    W[\Gamma_0]=H(\Gamma_t,\lambda_t)-H(\Gamma_0,\lambda_0).
  \]
  </p>

  <p>
    In the canonical case, the general expression for $\Delta S$ becomes
  </p>

  <p class="math" id="eq-DeltaS-canonical">
  \[
    \Delta S(\Gamma_0;t)
    =
    \ln\frac{Z(t)}{Z(0)}
    +\beta H(\Gamma_t,\lambda_t)
    -\beta H(\Gamma_0,\lambda_0).
  \]
  </p>

  <p>
    Using the work definition, this is
  </p>

  <p class="math" id="eq-DeltaS-work">
  \[
    \Delta S(\Gamma_0;t)
    =
    \ln\frac{Z(t)}{Z(0)}
    +\beta W[\Gamma_0].
  \]
  </p>

  <p>
    And since $\ln\frac{Z(t)}{Z(0)}=-\beta\Delta F$, we end up with the standard form
  </p>

  <p class="math" id="eq-DeltaS-betaW-DeltaF">
  \[
    \Delta S(\Gamma_0;t)=\beta\bigl(W[\Gamma_0]-\Delta F\bigr).
  \]
  </p>

  <p>
    Plug this into the integral fluctuation theorem:
  </p>

  <p class="math" id="eq-ift-to-jarzynski-1">
  \[
    \Bigl\langle
      \exp\bigl[-\beta\bigl(W[\Gamma_0]-\Delta F\bigr)\bigr]
    \Bigr\rangle_{\mathrm{rel},0}
    =1.
  \]
  </p>

  <p>
    But $\langle\cdot\rangle_{\mathrm{rel},0}$ is precisely the canonical average over the initial ensemble
    $\bar\rho(\Gamma,0)$, so this is equivalent to
  </p>

  <p class="math" id="eq-jarzynski">
  \[
    \bigl\langle e^{-\beta W}\bigr\rangle_{\mathrm{rel},0}=e^{-\beta\Delta F},
  \]
  </p>

  <p>
    which is Jarzynski’s equality. In other words: Jarzynski drops out as a special case of the classical Grabert
    fluctuation theorem for the entropy-production functional $\Delta S(\Gamma_0;t)$, when the relevant distribution
    is the canonical ensemble for the instantaneous Hamiltonian $H(\Gamma,\lambda_t)$ and the initial microscopic
    state coincides with the relevant state at $t=0$.
  </p>

</section>


      <!-- Second ad block (NO second AdSense script include) -->
      <ins class="adsbygoogle"
           style="display:block; text-align:center;"
           data-ad-layout="in-article"
           data-ad-format="fluid"
           data-ad-client="ca-pub-6719988103594554"
           data-ad-slot="2406334732"></ins>
      <script>
        (adsbygoogle = window.adsbygoogle || []).push({});
      </script>

      <p><a href="../blog.html">← Back to Blog</a></p>

    </main>
  </div>

  <script>
    async function loadSidebar() {
      const sidebarContainer = document.getElementById('sidebar');
      const response = await fetch('../partials/sidebar.html');
      const html = await response.text();
      sidebarContainer.innerHTML = html;

      const currentPath = window.location.pathname.split('/').pop();
      const links = sidebarContainer.querySelectorAll('a');
      links.forEach(link => {
        if (link.getAttribute('href') === currentPath) {
          link.classList.add('active');
        }
      });

      // Re-render KaTeX in case the injected sidebar contains math
      if (typeof renderMathInElement === "function") {
        renderMathInElement(document.querySelector("main.content"), {
          delimiters: [
            { left: "$$", right: "$$", display: true },
            { left: "\\[", right: "\\]", display: true },
            { left: "$", right: "$", display: false },
            { left: "\\(", right: "\\)", display: false }
          ],
          throwOnError: false,
          macros: { "\\mathbbm": "\\mathbb" },
          ignoredTags: ["script", "noscript", "style", "textarea", "pre", "code"]
        });
      }
    }
    loadSidebar();
  </script>
</body>
</html>
